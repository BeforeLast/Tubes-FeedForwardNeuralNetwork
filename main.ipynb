{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "75b19c9f-2bca-4a9a-a63d-0cc0c3f7eed9",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c5a04af-4125-423a-bed1-7598c7b02ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from classes.FFNN import FFNN\n",
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f12a622",
   "metadata": {},
   "source": [
    "# Load Datasets Iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d2ea3b9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150\n"
     ]
    }
   ],
   "source": [
    "iris = datasets.load_iris()\n",
    "x = iris.data\n",
    "y = []\n",
    "for test in iris.target : \n",
    "    temp = []\n",
    "    temp.append(test)\n",
    "    y.append(temp)\n",
    "print(len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9800f6ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150\n"
     ]
    }
   ],
   "source": [
    "print(len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6880cb15",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data split\n",
    "x_train = x[0:int(len(x)*0.9)] \n",
    "x_test = x[int(len(x)*0.9):]\n",
    "\n",
    "y_train = y[0:int(len(x)*0.9)] \n",
    "y_test = y[int(len(x)*0.9):]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a23efcff",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# Load Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e5db9e2-533a-4476-b917-aceab80aa10e",
   "metadata": {},
   "source": [
    "## Iris Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b94cf225-0fbd-4166-a70f-8b4ccec6e582",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTICE: MODEL Iris LOADED SUCCESSFULLY!\n"
     ]
    }
   ],
   "source": [
    "#iris model\n",
    "Model_Test = FFNN('./file/models/Iris_Model_Test.json')\n",
    "Model_Test.setLearningRate(0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b357c5f",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a86f7da5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 0 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 1 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 2 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 3 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 4 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 5 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 6 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 7 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 8 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 9 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 10 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 11 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 12 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 13 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 14 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 15 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 16 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 17 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 18 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 19 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 20 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 21 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 22 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 23 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 24 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 25 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 26 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 27 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 28 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 29 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 30 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 31 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 32 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 33 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 34 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 35 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 36 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 37 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 38 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 39 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 40 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 41 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 42 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 43 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 44 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 45 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 46 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 47 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 48 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 49 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 50 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 51 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 52 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 53 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 54 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 55 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 56 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 57 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 58 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 59 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 60 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 61 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 62 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 63 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 64 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 65 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 66 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 67 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 68 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 69 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 70 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 71 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 72 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 73 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 74 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 75 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 76 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 77 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 78 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 79 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 80 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 81 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 82 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 83 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 84 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 85 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 86 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 87 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 88 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 89 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 90 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 91 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 92 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 93 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 94 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 95 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 96 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 97 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 98 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 99 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 100 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 101 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 102 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 103 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 104 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 105 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 106 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 107 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 108 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 109 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 110 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 111 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 112 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 113 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 114 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 115 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 116 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 117 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 118 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 119 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 120 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 121 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 122 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 123 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 124 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 125 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 126 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 127 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 128 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 129 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 130 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 131 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 132 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 133 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 134 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 135 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 136 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 137 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 138 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 139 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 140 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 141 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 142 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 143 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 144 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 145 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 146 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 147 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 148 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 149 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 150 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 151 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 152 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 153 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 154 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 155 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 156 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 157 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 158 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 159 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 160 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 161 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 162 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 163 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 164 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 165 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 166 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 167 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 168 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 169 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 170 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 171 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 172 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 173 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 174 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 175 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 176 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 177 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 178 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 179 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 180 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 181 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 182 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 183 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 184 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 185 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 186 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 187 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 188 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 189 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 190 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 191 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 192 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 193 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 194 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 195 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 196 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 197 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 198 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 199 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Model successfully trained!\n",
      "Current cumulative error: 0.4999546031623447\n"
     ]
    }
   ],
   "source": [
    "#iris model\n",
    "#train using all of model\n",
    "Model_Test.train(x, y, 200, 1, 0.0000000000001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "075a6c29-38b2-4d3a-b4f4-772afcfc451f",
   "metadata": {},
   "source": [
    "## Batch Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5a078653-5337-42fe-805c-5f122462436b",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "07019a71-5a29-49ef-9cca-db10670cbc19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch prediction = \n",
      "\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "mymodel_predict = Model_Test.batch_predict(batch)\n",
    "print(f'Batch prediction = \\n')\n",
    "\n",
    "#reformat answers\n",
    "finalAns = []\n",
    "for item in mymodel_predict:\n",
    "    if item[0]>0.5:\n",
    "        finalAns.append(1)\n",
    "    else:\n",
    "        finalAns.append(0)\n",
    "print(finalAns)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "440c4439",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 2 1 2 2 1 1 2 1 1 1 2 1 1 2 1 2 1 2 1 2 2\n",
      " 1 1 1 2 2 1 1 1 1 2 2 2 1 1 2 2 2 2 1 1 2 2 2 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hizki\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1109: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Hizki\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "clf = MLPClassifier(random_state=1, max_iter=100)\n",
    "clf.fit(x,y)\n",
    "\n",
    "mlp_predict = clf.predict(x)\n",
    "print(mlp_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bee59b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import algorithm.Util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "63e5b5b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix: \n",
      "[[50, 0, 0], [0, 28, 22], [0, 0, 50]]\n",
      "we have multiple classified data = setosa, versicolor, virginica : 0,1,2 <- in that order\n",
      "accuracy: 0.8533333333333334\n",
      "macro precision: 0.8981481481481483\n",
      "macro recall: 0.8533333333333334\n",
      "macro f1 score: 0.8751674067808557\n"
     ]
    }
   ],
   "source": [
    "#kinerja sklearn \n",
    "confusionMatrix = algorithm.Util.findConfusionMatrix(iris.target, mlp_predict)\n",
    "print(\"confusion matrix: \", end=\"\\n\")\n",
    "print(confusionMatrix)\n",
    "print(\"we have multiple classified data = setosa, versicolor, virginica : 0,1,2 <- in that order\")\n",
    "print(\"accuracy: \" + str(algorithm.Util.getAccuracy(confusionMatrix)))\n",
    "print(\"macro precision: \" + str(algorithm.Util.getMacroPrecision(confusionMatrix)))\n",
    "print(\"macro recall: \" + str(algorithm.Util.getMacroRecall(confusionMatrix)))\n",
    "print(\"macro f1 score: \" + str(algorithm.Util.getMacroF1Score(confusionMatrix)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d6aab193",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix: \n",
      "[[0, 50, 0], [0, 50, 0], [0, 50, 0]]\n",
      "we have multiple classified data = setosa, versicolor, virginica : 0,1,2 <- in that order\n",
      "accuracy: 0.3333333333333333\n",
      "macro precision: 0.1111111111111111\n",
      "macro recall: 0.3333333333333333\n",
      "macro f1 score: 0.16666666666666666\n"
     ]
    }
   ],
   "source": [
    "#kinerja model\n",
    "confusionMatrix = algorithm.Util.findConfusionMatrix(iris.target, finalAns)\n",
    "print(\"confusion matrix: \", end=\"\\n\")\n",
    "print(confusionMatrix)\n",
    "print(\"we have multiple classified data = setosa, versicolor, virginica : 0,1,2 <- in that order\")\n",
    "print(\"accuracy: \" + str(algorithm.Util.getAccuracy(confusionMatrix)))\n",
    "print(\"macro precision: \" + str(algorithm.Util.getMacroPrecision(confusionMatrix)))\n",
    "print(\"macro recall: \" + str(algorithm.Util.getMacroRecall(confusionMatrix)))\n",
    "print(\"macro f1 score: \" + str(algorithm.Util.getMacroF1Score(confusionMatrix)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0a2876c",
   "metadata": {},
   "source": [
    "# Training Using Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "00d6085b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTICE: MODEL Iris LOADED SUCCESSFULLY!\n",
      "\n",
      "Epoch 0 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 1 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 2 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 3 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 4 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 5 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 6 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 7 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 8 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 9 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 10 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 11 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 12 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 13 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 14 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 15 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 16 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 17 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 18 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 19 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 20 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 21 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 22 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 23 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 24 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 25 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 26 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 27 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 28 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 29 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 30 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 31 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 32 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 33 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 34 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 35 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 36 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 37 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 38 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 39 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 40 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 41 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 42 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 43 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 44 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 45 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 46 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 47 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 48 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 49 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 50 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 51 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 52 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 53 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 54 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 55 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 56 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 57 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 58 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 59 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 60 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 61 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 62 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 63 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 64 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 65 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 66 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 67 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 68 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 69 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 70 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 71 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 72 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 73 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 74 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 75 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 76 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 77 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 78 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 79 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 80 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 81 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 82 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 83 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 84 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 85 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 86 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 87 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 88 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 89 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 90 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 91 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 92 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 93 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 94 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 95 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 96 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 97 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 98 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 99 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 100 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 101 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 102 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 103 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 104 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 105 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 106 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 107 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 108 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 109 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 110 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 111 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 112 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 113 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 114 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 115 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 116 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 117 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 118 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 119 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 120 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 121 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 122 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 123 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 124 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 125 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 126 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 127 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 128 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 129 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 130 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 131 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 132 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 133 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 134 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 135 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 136 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 137 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 138 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 139 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 140 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 141 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 142 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 143 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 144 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 145 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 146 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 147 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 148 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 149 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 150 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 151 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 152 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 153 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 154 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 155 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 156 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 157 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 158 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 159 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 160 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 161 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 162 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 163 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 164 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 165 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 166 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 167 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 168 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 169 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 170 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 171 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 172 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 173 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 174 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 175 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 176 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 177 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 178 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 179 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 180 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 181 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 182 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 183 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 184 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 185 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 186 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 187 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 188 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 189 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 190 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 191 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 192 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 193 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 194 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 195 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 196 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 197 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 198 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Epoch 199 / 200\n",
      "1/1 [==============================] loss:0\n",
      "Model successfully trained!\n",
      "Current cumulative error: 0.5000453977239546\n"
     ]
    }
   ],
   "source": [
    "#redefine model\n",
    "Model_Test = FFNN('./file/models/Iris_Model_Test.json')\n",
    "Model_Test.setLearningRate(0.01)\n",
    "#train using training data\n",
    "Model_Test.train(x_train, y_train, 200, 1, 0.0000000000001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "27bd8f6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch prediction = \n",
      "\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "#batch predict for test data\n",
    "mymodel_predict = Model_Test.batch_predict(x_test)\n",
    "print(f'Batch prediction = \\n')\n",
    "\n",
    "#reformat answers\n",
    "finalAns = []\n",
    "for item in mymodel_predict:\n",
    "    if item[0]>0.5:\n",
    "        finalAns.append(1)\n",
    "    else:\n",
    "        finalAns.append(0)\n",
    "print(finalAns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "de722aed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n",
      "confusion matrix: \n",
      "[[0, 0, 0], [0, 0, 0], [0, 15, 0]]\n",
      "we have multiple classified data = setosa, versicolor, virginica : 0,1,2 <- in that order\n",
      "accuracy: 0.0\n",
      "macro precision: 0.0\n",
      "macro recall: 0.0\n",
      "macro f1 score: 0\n"
     ]
    }
   ],
   "source": [
    "#kinerja utk training dengan split data\n",
    "#reformat karena y_test = [[0], [1], [1]] -> [0,1,2]\n",
    "y_final_test = [y_test[i][0] for i in range(len(y_test))]\n",
    "print(y_final_test)\n",
    "confusionMatrix = algorithm.Util.findConfusionMatrix(y_final_test, finalAns)\n",
    "print(\"confusion matrix: \", end=\"\\n\")\n",
    "print(confusionMatrix)\n",
    "print(\"we have multiple classified data = setosa, versicolor, virginica : 0,1,2 <- in that order\")\n",
    "print(\"accuracy: \" + str(algorithm.Util.getAccuracy(confusionMatrix)))\n",
    "print(\"macro precision: \" + str(algorithm.Util.getMacroPrecision(confusionMatrix)))\n",
    "print(\"macro recall: \" + str(algorithm.Util.getMacroRecall(confusionMatrix)))\n",
    "print(\"macro f1 score: \" + str(algorithm.Util.getMacroF1Score(confusionMatrix)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bcdc83d",
   "metadata": {},
   "source": [
    "# Train dengan 10-fold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a73ae182",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
